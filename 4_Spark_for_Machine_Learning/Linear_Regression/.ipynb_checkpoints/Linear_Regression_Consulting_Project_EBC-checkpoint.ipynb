{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Consulting Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Congratulations! You've been contracted by Hyundai Heavy Industries to help them build a predictive model for some ships. [Hyundai Heavy Industries](http://www.hyundai.eu/en) is one of the world's largest ship manufacturing companies and builds cruise liners.\n",
    "\n",
    "You've been flown to their headquarters in Ulsan, South Korea to help them give accurate estimates of how many crew members a ship will require.\n",
    "\n",
    "They are currently building new ships for some customers and want you to create a model and use it to predict how many crew members the ships will need.\n",
    "\n",
    "Here is what the data looks like so far:\n",
    "\n",
    "    Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "    ships.\n",
    "\n",
    "\n",
    "    Variables/Columns\n",
    "    Ship Name     1-20\n",
    "    Cruise Line   21-40\n",
    "    Age (as of 2013)   46-48\n",
    "    Tonnage (1000s of tons)   50-56\n",
    "    passengers (100s)   58-64\n",
    "    Length (100s of feet)  66-72\n",
    "    Cabins  (100s)   74-80\n",
    "    Passenger Density   82-88\n",
    "    Crew  (100s)   90-96\n",
    "    \n",
    "It is saved in a csv file for you called \"cruise_ship_info.csv\". Your job is to create a regression model that will help predict how many crew members will be needed for future ships. The client also mentioned that they have found that particular cruise lines will differ in acceptable crew counts, so it is most likely an important feature to include in your analysis! \n",
    "\n",
    "Once you've created the model and tested it for a quick check on how well you can expect it to perform, make sure you take a look at why it performs so well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Spark and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the input csv file.\n",
    "data = spark.read.csv('cruise_ship_info.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journey\n",
      "Azamara\n",
      "6\n",
      "30.276999999999997\n",
      "6.94\n",
      "5.94\n",
      "3.55\n",
      "42.64\n",
      "3.55\n"
     ]
    }
   ],
   "source": [
    "for r in data.head(1)[0]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------+----------+------+------+-----------------+----+\n",
      "|    line|age|tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+--------+---+-------+----------+------+------+-----------------+----+\n",
      "| Azamara|  6|  30276|       694|   594|   355|            42.64| 355|\n",
      "| Azamara|  6|  30276|       694|   594|   355|            42.64| 355|\n",
      "|Carnival| 26|  47262|      1486|   722|   743|             31.8| 670|\n",
      "|Carnival| 11| 110000|      2974|   952|  1488|            36.99|1910|\n",
      "|Carnival| 17| 101353|      2642|   892|  1321|            38.36|1000|\n",
      "|Carnival| 22|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival| 15|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival| 23|  70367|      2056|   855|  1022|            34.23| 919|\n",
      "|Carnival| 19|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival|  6| 110238|      3700|   951|  1487|            29.79|1150|\n",
      "|Carnival| 10| 110000|      2974|   951|  1487|            36.99|1160|\n",
      "|Carnival| 28|  46052|      1452|   727|   726|            31.72| 660|\n",
      "|Carnival| 18|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival| 17|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival| 11|  86000|      2124|   963|  1062|            40.49| 930|\n",
      "|Carnival|  8| 110000|      2974|   951|  1487|            36.99|1160|\n",
      "|Carnival|  9|  88500|      2124|   963|  1062|            41.67|1030|\n",
      "|Carnival| 15|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "|Carnival| 12|  88500|      2124|   963|  1162|            41.67| 930|\n",
      "|Carnival| 20|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "+--------+---+-------+----------+------+------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# format the columns\n",
    "cleaned_data = data.select([\n",
    "    data['Cruise_line'].alias('line'),\n",
    "    data['Age'].alias('age'),\n",
    "    (data['Tonnage']*1000).cast('integer').alias('tonnage'),\n",
    "    (data['passengers']*100).cast('integer').alias('passengers'),\n",
    "    (data['length']*100).cast('integer').alias('length'),\n",
    "    (data['cabins']*100).cast('integer').alias('cabins'),\n",
    "    data['passenger_density'],\n",
    "    (data['crew']*100).cast('integer').alias('crew')\n",
    "])\n",
    "cleaned_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- line: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- tonnage: integer (nullable = true)\n",
      " |-- passengers: integer (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- cabins: integer (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "|line|age|tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "|   0|  0|      0|         0|     0|     0|                0|   0|\n",
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list number of NANs or NULLs in each column\n",
    "from pyspark.sql.functions import count, when, isnan, col\n",
    "cleaned_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in cleaned_data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to clean, no nulls. Data looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert the 'line' string to a indexed integer so the vector assembler can create the features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "|line|age|tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "|16.0|  6|  30276|       694|   594|   355|            42.64| 355|\n",
      "|16.0|  6|  30276|       694|   594|   355|            42.64| 355|\n",
      "| 1.0| 26|  47262|      1486|   722|   743|             31.8| 670|\n",
      "| 1.0| 11| 110000|      2974|   952|  1488|            36.99|1910|\n",
      "| 1.0| 17| 101353|      2642|   892|  1321|            38.36|1000|\n",
      "| 1.0| 22|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0| 15|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0| 23|  70367|      2056|   855|  1022|            34.23| 919|\n",
      "| 1.0| 19|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0|  6| 110238|      3700|   951|  1487|            29.79|1150|\n",
      "| 1.0| 10| 110000|      2974|   951|  1487|            36.99|1160|\n",
      "| 1.0| 28|  46052|      1452|   727|   726|            31.72| 660|\n",
      "| 1.0| 18|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0| 17|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0| 11|  86000|      2124|   963|  1062|            40.49| 930|\n",
      "| 1.0|  8| 110000|      2974|   951|  1487|            36.99|1160|\n",
      "| 1.0|  9|  88500|      2124|   963|  1062|            41.67|1030|\n",
      "| 1.0| 15|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "| 1.0| 12|  88500|      2124|   963|  1162|            41.67| 930|\n",
      "| 1.0| 20|  70367|      2052|   855|  1019|            34.29| 919|\n",
      "+----+---+-------+----------+------+------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert line string to int \n",
    "from pyspark.ml.feature import StringIndexer\n",
    "string_indexer = StringIndexer(inputCol=\"line\", outputCol=\"line_index\")\n",
    "prepared_data = string_indexer.fit(cleaned_data).transform(cleaned_data)\n",
    "prepared_data = prepared_data.select([prepared_data['line_index'].alias('line'),'age','tonnage','passengers','length','cabins','passenger_density','crew'])\n",
    "prepared_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the vector assembler to create the features vector that will be fed to MLlib ,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helpers for vector assembling\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- line: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- tonnage: integer (nullable = true)\n",
      " |-- passengers: integer (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- cabins: integer (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[16.0,6.0,30276.0...| 355|\n",
      "|[16.0,6.0,30276.0...| 355|\n",
      "|[1.0,26.0,47262.0...| 670|\n",
      "|[1.0,11.0,110000....|1910|\n",
      "|[1.0,17.0,101353....|1000|\n",
      "|[1.0,22.0,70367.0...| 919|\n",
      "|[1.0,15.0,70367.0...| 919|\n",
      "|[1.0,23.0,70367.0...| 919|\n",
      "|[1.0,19.0,70367.0...| 919|\n",
      "|[1.0,6.0,110238.0...|1150|\n",
      "|[1.0,10.0,110000....|1160|\n",
      "|[1.0,28.0,46052.0...| 660|\n",
      "|[1.0,18.0,70367.0...| 919|\n",
      "|[1.0,17.0,70367.0...| 919|\n",
      "|[1.0,11.0,86000.0...| 930|\n",
      "|[1.0,8.0,110000.0...|1160|\n",
      "|[1.0,9.0,88500.0,...|1030|\n",
      "|[1.0,15.0,70367.0...| 919|\n",
      "|[1.0,12.0,88500.0...| 930|\n",
      "|[1.0,20.0,70367.0...| 919|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create and configure the vector assembler with the desired 'features' columns\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['line','age','tonnage','passengers','length','cabins','passenger_density'],\n",
    "    outputCol='features')\n",
    "\n",
    "# assemble the 'features'\n",
    "final_data = assembler.transform(prepared_data).select('features', 'crew')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the features\n",
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=2.0)\n",
    "final_data_norm = normalizer.transform(final_data).select('features', 'crew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "train_data, test_data = final_data_norm.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|               119|\n",
      "|   mean| 765.0840336134454|\n",
      "| stddev|359.19162016554816|\n",
      "|    min|                59|\n",
      "|    max|              2100|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|               39|\n",
      "|   mean|822.7948717948718|\n",
      "| stddev|322.2279496753142|\n",
      "|    min|               60|\n",
      "|    max|             1220|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load linear regression lib\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression(featuresCol='features', labelCol='crew', predictionCol='crew_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with the training data\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [5.711237343146823,-1.7045758708090215,0.0008952993351538641,-0.17374051831234982,0.44556166824166077,0.898309688065081,-0.5590078925005209]\n",
      "Intercept: -91.83804833736346\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients and intercept for linear regression\n",
    "# Coefficients => 'line','age','tonnage','passengers','length','cabins','passenger_density'\n",
    "print(\"Coefficients: {}\\nIntercept: {}\".format(lr_model.coefficients,lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model with the test_data\n",
    "test_results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  58.027712993596346\n",
      "MSE:  4645.7213949757215\n",
      "RMSE: 68.159529010812\n",
      "R2:   0.9540793786250188\n"
     ]
    }
   ],
   "source": [
    "# print some statistical evaluation indicators of the model\n",
    "print('MAE:  {}\\nMSE:  {}\\nRMSE: {}\\nR2:   {}'.format(test_results.meanAbsoluteError, \n",
    "                                                       test_results.meanSquaredError,\n",
    "                                                       test_results.rootMeanSquaredError,\n",
    "                                                       test_results.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              158|\n",
      "|   mean|779.3291139240506|\n",
      "| stddev|350.3192255413956|\n",
      "|    min|               59|\n",
      "|    max|             2100|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analyze indicators against original data\n",
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RMSE of 68.15 over an average crew value of 779, not bad\n",
    "* R-squared indicates that this model explains 95% of the train data variance, good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to unlabeled data\n",
    "Assuming the test data is unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of unlabeled data using the test_data\n",
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model and predict 'expenditure'\n",
    "crew_predictions = lr_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|         crew_pred|\n",
      "+--------------------+------------------+\n",
      "|[0.0,12.0,90090.0...| 885.1139933784553|\n",
      "|[0.0,12.0,138000....|1298.1506698994644|\n",
      "|[0.0,18.0,70000.0...| 800.4584751713626|\n",
      "|[0.0,25.0,73192.0...| 835.5948961533312|\n",
      "|[1.0,6.0,110238.0...|1102.3646316669308|\n",
      "|[1.0,8.0,110000.0...|1220.8531581523084|\n",
      "|[1.0,9.0,110000.0...|1219.5941439497412|\n",
      "|[1.0,11.0,86000.0...| 963.5402820291749|\n",
      "|[1.0,12.0,88500.0...| 1053.245293989608|\n",
      "|[1.0,14.0,101509....|1065.6903046719608|\n",
      "|[1.0,20.0,70367.0...| 863.4300741805278|\n",
      "|[1.0,22.0,70367.0...| 860.0209224389097|\n",
      "|[2.0,6.0,113000.0...|1159.1333307263908|\n",
      "|[2.0,7.0,116000.0...|1274.3907668406118|\n",
      "|[2.0,9.0,116000.0...|1122.9614275964393|\n",
      "|[2.0,11.0,108977....|1115.3470989009272|\n",
      "|[2.0,15.0,108806....|1107.8416408167145|\n",
      "|[2.0,16.0,77499.0...| 925.3129917172189|\n",
      "|[2.0,29.0,44348.0...| 555.6462180224939|\n",
      "|[3.0,11.0,85000.0...| 889.6262299749642|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crew_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
